# 매개변수 갱신

## SGD(확률적 경사 하강법, Stochastic Gradient Descent)
- $\eta$: 학습률 </br>
$$W \leftarrow W - \eta\frac{\partial L}{\partial W}$$
- 전체를 한 번에 계산하지 않고, 확률적으로 일부 샘플을 뽑아 조금씩 나누어 학습을 하는 과정
- 반복할 때마다 다루는 데이터의 수가 적기 때문에 한 번 처리하는 속도는 빠름
- 확률적이기 때문에, 배치 경사하강법보다 불안정
- 손실함수의 최솟값에 이를 때까지 다소 위아래롤 요동치면서 이동
- 위와 같은 문제 때무넹 미니 배치 경사하강법(mini-batch gradient descent)로 학습을 진행


## Momentum
- $\alpha$: 관성계수
- $v$: 속도 </br>
$$v \leftarrow \alpha v - \eta\frac{\partial L}{\partial W}$$
$$W \leftarrow W + v$$
- 운동량을 의미, 관선과 관련
- 공이 그릇의 경사면을 따라서 내려가는 듯한 모습
- 이전의 속도를 유지하려는 성향
  - 경사 하강을 좀 더 유지하려는 성격을 지님
- 단순히 SGD만 사용하는 것보다 적게 방향이 변함
  <img width="800" alt="image" src="https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/d170bf4b-9bf2-4c7c-a554-0ead3d837b04">


## AdaGrad(Adaptive Gradient)
- $h$: 기존 기울기를 제곱하여 더한 값 </br>
$$h \leftarrow h + \frac{\partial L}{\partial W} \odot \frac{\partial L}{\partial W}$$
$$W \leftarrow - \eta \frac{1}{\sqrt{h}} \frac{\partial L}{\partial W}$$
- 가장 가파른 경사를 따라 빠르게 하강하는 방법
- 적응적 학습률이라고도 하며 학습률을 변화시키며 진행
- 경사가 급할 때는 빠르게 변화, 완만할 때는 느리게 변화
- 간단한 문제에서는 좋을 수는 있지만 딥러닝에서는 자주 쓰이지 않음
  - 학습률이 너무 감소되어 global minimum에 도달하기 전에 학습이 빨리 종료될 수 있기 때문
- 과거의 기울기를 제곱하여 계속 더해가기 때문에 학습을 진행할수록 갱신 강도가 약해짐($\because \frac{1}{\sqrt h}$)


## RMSProp(Root Mean Square Propagation)
- $h$: 기존 기울기를 제곱하여 업데이트 계수를 곱한 값과 업데이트 계수를 곱한 값을 더해줌
- $\rho$: 지수 평균의 업데이트 계수
$$h \leftarrow \rho h + (1 - \rho)\frac{\partial L}{\partial W} \odot \frac{\partial L}{\partial W}$$
$$W \leftarrow W - \frac{\eta \frac{\partial L}{\partial W}}{\sqrt{h} + \epsilon}$$
- AdaGrad를 보완하기 위한 방법으로 등장
- 합 대신 지수의 평균값을 활용
- 학습이 안 되기 시작하면 학습률이 커져 잘 되게끔하고, 학습률이 너무 크면 학습률을 다시 줄임


## Adam(Adaptive Moment Estimation)
- $\beta$: 지수 평균의 업데이트 계수
- $\beta_1 \approx 0.9, \beta2 \approx 0.999$
$$t \leftarrow t + 1$$
$$m_t \leftarrow \beta_1m_{t-1} + (1 - \beta_1)\frac{\partial L}{\partial W}$$
$$v_t \leftarrow \beta_2v_{t-1} + (1 - \beta_2)\frac{\partial L}{\partial W} \odot \frac{\partial L}{\partial W}$$
$$\eta \leftarrow \frac{\eta \sqrt{1 - \beta_2^t}}{1 - \beta_1^t}$$
$$\hat{m_t} \leftarrow \frac{m_t}{1-\beta^t_1}$$
$$\hat{v_t} \leftarrow \frac{v_t}{1-\beta^t_2}$$
$$W_t \leftarrow W_{t-1} - \frac{\eta\hat{m_t}}{\sqrt{\hat{v_t}} + \epsilon}$$
- Momentum 최적화와 RMSProp의 아이디어를 합친 것
- 지난 그래디언트의 지수 감소 평균을 따르고(Momentum), 지난 그래디언트 **제곱의** 지수 감소 평균(RMSProp)을 따름
- 가장 많이 사용되는 최적화 방법


# 가중치 초깃값 설정

## 초깃값: 0(Zeros)
- 학습이 올바르게 진행되지 않음
- 오차역전파법에서 모든 가중치의 값이 똑같이 갱신됨
  <img width="800" alt="image" src=https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/ac30f728-b8e4-4de0-b8d8-5f83a54c0b35>


## 초깃값: 균일분포(Uniform)
- 활성화 값이 균일하지 않음(활성화함수: Sigmoid)
- 역전파로 전해지는 기울기값이 사라짐
 <img width="800" alt="image" src=https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/e4bf190c-4286-461a-a371-56a28fca963a>


## 초깃값: 정규분포(Normalization)
- 활성화함수를 통과하면 양쪽으로 퍼짐
- 0과 1에 퍼지면서 기울기 소실문제 발생
<img width="800" alt="image" src=https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/1ced6fcb-1ba4-4bf0-8792-4f5cb99b59fd>


## 초깃값: 가중치 표준편차 = 0.01
- 0과 1로 퍼지지는 않고, 한 곳에 치우쳐 짐
- 해당 신경망이 표현할 수 있는 문제가 제한됨
  <img width="800" alt="image" src=https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/91aad4e7-df22-4e99-b92c-b9ec96e08cf6>


## 초깃값: Xavier
- 은닉층의 노드 수가 n이라면 표준편차가 $\frac{1}{\sqrt{n}}$인 분포
- 더 많은 가중치에 역전파가 전달 가능하고, 비교적 많은 문제를 표현할 수 있음
- 활성화함수가 **선형**인 함수(ex. Sigmoid)일 때 매우 적합
  <img width="800" alt="image" src=https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/c509638e-b9b0-4a45-b2d6-4b2e08e96287>


## 초깃값: He
- 은닉층의 노드 수가 n이라면 표준편차가 $\sqrt{\frac{2}{n}}$인 분포
- 활성화값 분포가 균일하게 분포되어 있음
- 활성화함수가 **비선형** 함수(ex. ReLU)일 때 매우 적합
  <img width="800" alt="image" src=https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/ccda781e-7693-4cec-a52a-9b78eb18cc8b>


# 규제화(Regularization) - 가중치 감소
- 과대적합(Overfitting)을 방지하는 방법 중 하나
- 과대적합은 가중치의 매개변수 값이 커서 발생하는 경우가 많음
  - 이를 방지하기 위해 큰 가중치 값에 큰 규제를 가하는 것
- 규제란 가중치의 절대값을 가능한 작게 만드는 것으로, 가중치의 모든 원소를 0에 가깝게 하여 모든 피처가 출력에 주는 영향을 최소한으로 만드는 것(기울기를 작게 만드는 것)을 의미함. 즉 규제란 과대적합이 되지 않도록 모델을 가제로 제한한다는 의미
- 처음 가중치가 크면 손실함수의 값이 커지고, 그 후 갱신되는 가중치는 크게 감소함
  - 따라서 가중치에 규제를 주어 가중치의 값을 크게 하고 손실함수의 값 또한 커지게 함
- 적절한 규제값을 찾는 것이 중요함


## L2 규제
$$Cost = \frac{1}{n} \displaystyle\sum_{i=1}^{n} L(y_i, \hat{y_i}) + \frac{\lambda}{2}w^2$$
- 가중치의 제곱합
- 손실 함수에 일정 값을 더함으로써 과적합을 방지
- $\lambda$값이 크면 가중치 감소가 커지고, 작으면 가하는 규제가 적어짐
- 다양한 상황에 적응하여 예상치 못한 입력이나 환경 변화에도 견고한 성능을 유지하고, 오류에 민감하지 않은 모델들이 더 생성(Robust)되므로 L1보다 많이 사용됨


## L1 규제
$$Cost = \frac{1}{n} \displaystyle\sum_{i=1}^{n} L(y_i, \hat{y_i}) + \frac{\lambda}{2}|w|$$
- 가중치의 절대값합
- L2 규제와 달리 어떤 가중치는 0이 되는데 이는 모델이 가벼워짐을 의미


## BatchNormalization(배치 정규화)
<img width="800" alt="image" src="https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/06008241-b06a-4f7c-bd6d-cf31c0a655a6"> </br>
- 각 층에서의 활성화값이 적당히 분포되도록 조정하는 것
- 공변량 변화로 인해 데이터의 분포가 계층을 지날 때마다 기울어지는 현상이 발생할 수 있음
  - 이를 해결하기 위해 정규분포화 시켜주는 것임
- 미니배치 입력 데이터를 평균 0, 분산 1인 데이터로 변환하는 일
$$[학습단계]$$
$$\mu_B \leftarrow \frac{1}{m} \displaystyle\sum_{i=1}^{m} x_i$$
$$\sigma_B^2 \leftarrow \frac{1}{m} \displaystyle\sum_{i=1}^{m} (x_i - \mu_B)^2$$
$$\hat{x_i} \leftarrow \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$$
- 배치 정규화 계층마다 이 정규화된 데이터에 고유한 확대($\gamma$)와 이동($\beta$) 변환을 수행함
  - 이는 정규화된 데이터가 N(0, 1)이 되므로 입력값의 95%는 Sigmoid 함수에서 그래프의 중간 구간에 속하게 됨
  - Sigmoid 함수 그래프의 중간 구간은 선형이 되는 구간이기 때문에 비선형의 성질을 잃게 됨
  - 이로 인하여 신경망의 성립 자체가 불가함
  - 따라서 $\gamma$를 곱해주고 $\beta$를 더해줌 </br>
$$y_i \leftarrow \gamma\hat{x_i} + \beta$$
- 추론 단계에서는 학습 단계에서 배치 단위의 평균과 분산을 저장한 값을 이용해 정규화를 수행함
  - 이동 평균 방식을 이용하여 평균과 분산을 산출함 </br>
$$[추론단계]$$
$$\hat{\mu} \leftarrow \alpha\hat{\mu} + (1 - \alpha)\mu_B^{(i)}$$
$$\hat{\sigma} \leftarrow \alpha\hat{\sigma} + (1 - \alpha)\sigma_B^{(i)}$$


## Dropout
- 학습할 때 사용하는 노드의 수를 전체 노드 중에서 일부만을 사용
- 보통 비율을 0.5 또는 0.7로 설정
  <img width="800" alt="image" src="https://github.com/y100861/deep-learning-from-scratch-master/assets/107607076/5fffff0e-11aa-4f6a-9894-1671b43084d3">
